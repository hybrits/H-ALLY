{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1bqHXL3XR7SmbCJ-IlX8mNRqwjcXP1Qdc",
      "authorship_tag": "ABX9TyMOVWvtFJ7fh0OxQUmgiL9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hybrits/H-ALLY/blob/main/Primer_entramientoV_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset_limpio1.csv')\n",
        "\n",
        "# Crear un mapeo de etiquetas único para cada valor en la columna 'Título'\n",
        "label_mapping = {label: idx for idx, label in enumerate(df['Título'].unique())}\n",
        "\n",
        "# Aplicar el mapeo de etiquetas a la columna 'Título'\n",
        "df['Título'] = df['Título'].map(label_mapping)\n",
        "\n",
        "# Verificar los valores NaN en 'Título'\n",
        "nan_titles = df['Título'].isna()\n",
        "print(\"Filas con NaN en 'Título':\")\n",
        "print(df[nan_titles])\n",
        "\n",
        "# Manejar valores NaN: Opción 1 - Eliminar filas con NaN\n",
        "df = df.dropna(subset=['Título'])\n",
        "\n",
        "# Convertir 'Título' a enteros después de manejar NaN\n",
        "df['Título'] = df['Título'].astype(int)\n",
        "\n",
        "# Verificar que no queden NaN en 'Título'\n",
        "print(\"Número de valores NaN en 'Título' después de la limpieza:\", df['Título'].isna().sum())\n",
        "\n",
        "# Asegurarse de que todos los valores en 'Contenido' sean cadenas de texto\n",
        "df['Contenido'] = df['Contenido'].fillna('').astype(str)\n",
        "\n",
        "# Tokenización usando DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "train_encodings = tokenizer(df['Contenido'].tolist(), truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_encodings['input_ids'], df['Título'], test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Datos preparados para el entrenamiento.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD9FhCpIfIUW",
        "outputId": "e92f4d3f-08e0-44ee-e845-524a76d20402"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas con NaN en 'Título':\n",
            "Empty DataFrame\n",
            "Columns: [Título, URL, Autor, Fecha, Contenido]\n",
            "Index: []\n",
            "Número de valores NaN en 'Título' después de la limpieza: 0\n",
            "Datos preparados para el entrenamiento.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gYty8dTYaqg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Verificar si hay una GPU disponible y configurarla para el entrenamiento\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Crear el modelo\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_mapping))\n",
        "model.to(device)\n",
        "\n",
        "# Definir los argumentos de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Directorio de salida para guardar los resultados\n",
        "    num_train_epochs=3,              # Número de épocas de entrenamiento\n",
        "    per_device_train_batch_size=8,   # Tamaño del lote por dispositivo durante el entrenamiento\n",
        "    per_device_eval_batch_size=8,    # Tamaño del lote por dispositivo durante la evaluación\n",
        "    warmup_steps=500,                # Número de pasos para el calentamiento\n",
        "    weight_decay=0.01,               # Tasa de decaimiento del peso\n",
        "    logging_dir='./logs',            # Directorio de registro para TensorBoard\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\"            # Evaluación al final de cada época\n",
        ")\n",
        "\n",
        "# Convertir las entradas y etiquetas de entrenamiento y prueba a tensores de PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.long).detach().clone()\n",
        "X_test = torch.tensor(X_test, dtype=torch.long).detach().clone()\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long).detach().clone()\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long).detach().clone()\n",
        "\n",
        "# Crear un dataset a partir de las entradas y etiquetas\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Crear datasets de entrenamiento y prueba\n",
        "train_dataset = CustomDataset(\n",
        "    {\n",
        "        'input_ids': X_train,\n",
        "        'attention_mask': train_encodings['attention_mask'][:len(X_train)]\n",
        "    },\n",
        "    y_train\n",
        ")\n",
        "\n",
        "test_dataset = CustomDataset(\n",
        "    {\n",
        "        'input_ids': X_test,\n",
        "        'attention_mask': train_encodings['attention_mask'][len(X_train):]\n",
        "    },\n",
        "    y_test\n",
        ")\n",
        "\n",
        "# Crear el entrenador\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Entrenar el modelo\n",
        "trainer.train()\n",
        "\n",
        "# Evaluar el modelo\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "xhx62qQ7dFKB",
        "outputId": "1cc15ee2-d032-477a-ed0e-68a4194af7af"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1818' max='5451' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1818/5451 11:19 < 22:38, 2.67 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='411' max='455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [411/455 00:49 < 00:05, 8.26 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1919' max='5451' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1919/5451 12:50 < 23:40, 2.49 it/s, Epoch 1.06/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>6.910200</td>\n",
              "      <td>7.034701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5b40ca7d870b>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Entrenar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Evaluar el modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2271\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2274\u001b[0m                 ):\n\u001b[1;32m   2275\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo y el tokenizador\n",
        "model.save_pretrained('./trained_model')\n",
        "tokenizer.save_pretrained('./trained_model')\n"
      ],
      "metadata": {
        "id": "iHzKmCdOgIsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "\n",
        "# Cargar el modelo y el tokenizador guardados\n",
        "model = DistilBertForSequenceClassification.from_pretrained('./trained_model')\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('./trained_model')\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "aiKiJgxhgQ-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nueva consulta\n",
        "new_query = [\"Mi computadora se reinicia sola después de hacer overclocking, ¿qué puedo hacer?\"]\n",
        "\n",
        "# Tokenizar la nueva consulta\n",
        "inputs = tokenizer(new_query, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "\n",
        "# Mover los tensores a la GPU si está disponible\n",
        "inputs = {key: val.to(device) for key, val in inputs.items()}\n"
      ],
      "metadata": {
        "id": "RFHCyP8ZgUZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Poner el modelo en modo de evaluación\n",
        "model.eval()\n",
        "\n",
        "# Desactivar el cálculo de gradientes para la predicción\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Obtener las predicciones\n",
        "logits = outputs.logits\n",
        "predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# Convertir las predicciones a etiquetas legibles\n",
        "predicted_labels = [list(label_mapping.keys())[list(label_mapping.values()).index(pred)] for pred in predictions]\n",
        "\n",
        "print(f\"Categoría predicha: {predicted_labels[0]}\")\n"
      ],
      "metadata": {
        "id": "9UEjoCnNga2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}